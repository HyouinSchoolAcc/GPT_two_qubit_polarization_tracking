{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "144526b3-138c-46db-bf9f-b253efda5e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "import random\n",
    "import math\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from collections import deque, namedtuple\n",
    "import time\n",
    "import gym\n",
    "from gym import spaces\n",
    "import copy\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e73220fb-cd78-4049-8c41-7a9affad0465",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_feature_dim = 3  # Each input element is a 1x3 vector\n",
    "embed_size = 128\n",
    "target_dim = 3\n",
    "block_size = 100\n",
    "num_heads = 32\n",
    "max_iters = 1200\n",
    "batch_size = 32\n",
    "eval_iters = 200\n",
    "eval_interval = 10\n",
    "num_layers=12\n",
    "\n",
    "def get_batch3(split):\n",
    "    # Select the correct data split\n",
    "    if split == 'train':\n",
    "        a, b, max_index = x_train, y_train, int(length_read * 0.9) - block_size - 1\n",
    "    else:  # split == 'test'\n",
    "        a, b, max_index = x_test, y_test, length_read - (int(length_read * 0.9) + block_size + 1)\n",
    "\n",
    "    # Generate random indices for batch selection, ensuring they're within bounds\n",
    "    ix = torch.randint(0, max_index, (batch_size,))\n",
    "    # Initialize lists to hold the batches\n",
    "    x_batch = []\n",
    "    y_batch = []\n",
    "\n",
    "    for i in ix:\n",
    "        try:\n",
    "            # Extract sequences from 'a' and 'b' and the corresponding target from 'b'\n",
    "            seq_A = torch.tensor(a.iloc[i.item():i.item() + block_size+1].astype(np.float32).values, dtype=torch.float32)\n",
    "            seq_B = torch.tensor(b.iloc[i.item():i.item() + block_size].astype(np.float32).values, dtype=torch.float32)\n",
    "            target = torch.tensor(b.iloc[i.item() + block_size].astype(np.float32).values, dtype=torch.float32)\n",
    "\n",
    "            seq = torch.cat((seq_A, seq_B), dim=0)\n",
    "            x_batch.append(seq)\n",
    "            y_batch.append(target)\n",
    "        except IndexError as e:\n",
    "            print(f\"IndexError for index {i.item()}: {str(e)}\")\n",
    "            print(f\"Attempting to access index [{i.item()}:{i.item() + block_size}] in 'a' with shape {a.shape}\")\n",
    "            print(f\"Attempting to access index {i.item() + block_size} in 'b' with shape {b.shape}\")\n",
    "            # Optionally, break or continue depending on desired behavior on error\n",
    "            break  # or continue\n",
    "\n",
    "    if not x_batch or not y_batch:\n",
    "        print(\"Error: Batch could not be created due to index issues.\")\n",
    "        return None, None\n",
    "\n",
    "    # Stack the collected sequences and targets into tensors\n",
    "    xstack = torch.stack(x_batch)\n",
    "    ystack = torch.stack(y_batch)\n",
    "\n",
    "    return xstack, ystack\n",
    "\n",
    "\n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, embed_size):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.embed_size = embed_size\n",
    "\n",
    "        self.keys = nn.Linear(embed_size, embed_size, bias=False)\n",
    "        self.queries = nn.Linear(embed_size, embed_size, bias=False)\n",
    "        self.values = nn.Linear(embed_size, embed_size, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        K = self.keys(x)\n",
    "        Q = self.queries(x)\n",
    "        V = self.values(x)\n",
    "\n",
    "        attention_scores = torch.matmul(Q, K.transpose(-2, -1)) / self.embed_size ** 0.5\n",
    "        attention = torch.softmax(attention_scores, dim=-1)\n",
    "\n",
    "        attended = torch.matmul(attention, V)\n",
    "        return attended\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, embed_size, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.embed_size = embed_size\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "        assert embed_size % num_heads == 0\n",
    "\n",
    "        self.head_dim = embed_size // num_heads\n",
    "\n",
    "        self.keys = nn.Linear(embed_size, embed_size, bias=False)\n",
    "        self.queries = nn.Linear(embed_size, embed_size, bias=False)\n",
    "        self.values = nn.Linear(embed_size, embed_size, bias=False)\n",
    "\n",
    "        self.fc_out = nn.Linear(embed_size, embed_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, seq_length, _ = x.shape\n",
    "        keys = self.keys(x).view(batch_size, seq_length, self.num_heads, self.head_dim)\n",
    "        queries = self.queries(x).view(batch_size, seq_length, self.num_heads, self.head_dim)\n",
    "        values = self.values(x).view(batch_size, seq_length, self.num_heads, self.head_dim)\n",
    "\n",
    "        attention_scores = torch.einsum(\"bnqh,bnkh->bnqk\", [queries, keys]) / (self.head_dim ** 0.5)\n",
    "        attention = torch.softmax(attention_scores, dim=-1)\n",
    "\n",
    "        attended = torch.einsum(\"bnqk,bnkv->bnqv\", [attention, values]).reshape(batch_size, seq_length, self.embed_size)\n",
    "\n",
    "        output = self.fc_out(attended)\n",
    "        return output\n",
    "        \n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, embed_size, num_heads):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.norm1 = nn.LayerNorm(embed_size)\n",
    "        self.attention = MultiHeadAttention(embed_size, num_heads)\n",
    "        self.dropout1 = nn.Dropout(0.1)\n",
    "\n",
    "        self.norm2 = nn.LayerNorm(embed_size)\n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(embed_size, 2 * embed_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2 * embed_size, embed_size),\n",
    "        )\n",
    "        self.dropout2 = nn.Dropout(0.1)\n",
    "\n",
    "    def forward(self, value):\n",
    "        x = self.norm1(value)\n",
    "        attention_output = self.attention(x)\n",
    "        x = value + self.dropout1(attention_output)  # Residual connection and dropout after attention\n",
    "        x = self.norm2(x)\n",
    "        feed_forward_output = self.feed_forward(x)\n",
    "        out = value + self.dropout2(feed_forward_output)  # Residual connection and dropout after FFN\n",
    "        return out\n",
    "\n",
    "# Positional Encoding in Encoder class should be moved to the device\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_feature_dim, embed_size, num_heads, num_layers, seq_length):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.input_fc = nn.Linear(input_feature_dim, embed_size)\n",
    "        self.positional_encoding = nn.Parameter(torch.randn(1, seq_length, embed_size)).to(device)\n",
    "        self.layers = nn.ModuleList([\n",
    "            TransformerBlock(embed_size, num_heads) for _ in range(num_layers)])\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.input_fc(x)) + self.positional_encoding\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "    \n",
    "    def to_cpu(self):\n",
    "        # Move the entire model to CPU\n",
    "        self.input_fc.to('cpu')\n",
    "        self.positional_encoding.data = self.positional_encoding.data.cpu()\n",
    "        for layer in self.layers:\n",
    "            layer.to('cpu')\n",
    "        self.relu.to('cpu')\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "class EncoderDecoderModelWithMultiHeadAttention(nn.Module):\n",
    "    def __init__(self, input_feature_dim, embed_size, target_dim, seq_length, num_heads, num_layers):\n",
    "        super(EncoderDecoderModelWithMultiHeadAttention, self).__init__()\n",
    "        self.encoder = Encoder(input_feature_dim, embed_size, num_heads, num_layers, seq_length)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(embed_size, target_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, targets):\n",
    "        encoded = self.encoder(x)\n",
    "        encoded_pooled = torch.mean(encoded, dim=1)\n",
    "        decoded = self.decoder(encoded_pooled)\n",
    "        \n",
    "        if targets is not None:\n",
    "            loss = criterion(decoded, targets)  \n",
    "            return decoded, loss\n",
    "\n",
    "\n",
    "        return decoded, None\n",
    "\n",
    "    def to_cpu(self):\n",
    "        self.encoder.to_cpu()\n",
    "        for layer in self.decoder:\n",
    "            layer.to('cpu')\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3aaf48c-75ca-4091-bef6-c1d21fec6fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "def start_time():\n",
    "    return time.time()\n",
    "\n",
    "def elapsed(a):\n",
    "    return time.time()-a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9948a926-6d36-47fe-8801-8286f54ca0ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from C:/Users/yueze/Desktop/trained_model.pth\n"
     ]
    }
   ],
   "source": [
    "model_path = \"C:/Users/yueze/Desktop/trained_model.pth\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "modelt = EncoderDecoderModelWithMultiHeadAttention(input_feature_dim, embed_size, target_dim, block_size+1, num_heads, num_layers)\n",
    "modelt.load_state_dict(torch.load(model_path, map_location=device))\n",
    "modelt.to(device)\n",
    "print(\"Model loaded from\", model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2be1ae3-ef67-431b-9fc4-536aac6c2c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyHardware:\n",
    "    \"\"\"Simulates hardware behavior for the environment.\"\"\"\n",
    "    @staticmethod\n",
    "    def implement(actions,t, measurement_1350, measurement_1550):\n",
    "        # Apply action effects with cosine function\n",
    "        measurement_1350 += actions * 0.3 * np.cos(actions)+ np.sin(t)\n",
    "        # Wrap around if the value exceeds 2.2 or goes below -2.2\n",
    "        \n",
    "        while np.any(measurement_1350 > 2.2) or np.any(measurement_1350 < -2.2):\n",
    "            measurement_1350 = np.where(measurement_1350 > 2.2, measurement_1350 - 4.4, measurement_1350)\n",
    "            measurement_1350 = np.where(measurement_1350 < -2.2, measurement_1350 + 4.4, measurement_1350)\n",
    "        \n",
    "        # Apply action to 1550 nm state with a multiplier of 1\n",
    "        measurement_1550 += actions * np.cos(3 * actions) + np.sin(3 * t)\n",
    "        \n",
    "        while np.any(measurement_1550 > 2.2) or np.any(measurement_1550 < -2.2):\n",
    "            measurement_1550 = np.where(measurement_1550 > 2.2, measurement_1550 - 4.4, measurement_1550)\n",
    "            measurement_1550 = np.where(measurement_1550 < -2.2, measurement_1550 + 4.4, measurement_1550)    \n",
    "        return measurement_1350, measurement_1550    \n",
    "\n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def drift(t, measurement_1350, measurement_1550):\n",
    "        # Apply action effects with cosine function\n",
    "        measurement_1350 += np.sin(t)\n",
    "        while np.any(measurement_1350 > 2.2) or np.any(measurement_1350 < -2.2):\n",
    "            measurement_1350 = np.where(measurement_1350 > 2.2, measurement_1350 - 4.4, measurement_1350)\n",
    "            measurement_1350 = np.where(measurement_1350 < -2.2, measurement_1350 + 4.4, measurement_1350)\n",
    "        measurement_1550 += np.sin(3 * t)\n",
    "        while np.any(measurement_1550 > 2.2) or np.any(measurement_1550 < -2.2):\n",
    "            measurement_1550 = np.where(measurement_1550 > 2.2, measurement_1550 - 4.4, measurement_1550)\n",
    "            measurement_1550 = np.where(measurement_1550 < -2.2, measurement_1550 + 4.4, measurement_1550)\n",
    "   \n",
    "        return measurement_1350, measurement_1550\n",
    "\n",
    "    @staticmethod\n",
    "    def measure(wavelength, t, initial_state_1550=None):\n",
    "        # Simulate a hardware measurement with random values within a range\n",
    "        if wavelength == 1350:\n",
    "            return env.optimal_state + np.sin(t)\n",
    "        elif wavelength == 1550 and initial_state_1550 is not None:\n",
    "            return initial_state_1550 + np.sin(3 * t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28996a07-65be-4c42-9db6-fd7f5be0ed87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example input size: torch.Size([1, 306])\n",
      "state size: 306\n",
      "Initial state: [[ 0.29914352  0.3150803   0.22205301  0.01972802  0.0356648  -0.05736249\n",
      "   0.43184651  0.44778329  0.35475599 -0.10472641 -0.08878963 -0.18181693\n",
      "   0.54556143  0.56149821  0.46847091 -0.20542582 -0.18948904 -0.28251633\n",
      "   0.63122982  0.6471666   0.55413931 -0.27434854 -0.25841176 -0.35143906\n",
      "   0.68202739  0.69796417  0.60493687 -0.30600424 -0.29006745 -0.38309475\n",
      "   0.69390762  0.70984441  0.61681711 -0.29787123 -0.28193445 -0.37496174\n",
      "   0.66592416  0.68186094  0.58883364 -0.25059739 -0.23466061 -0.32768791\n",
      "   0.60030613  0.61624292  0.52321562 -0.16794853 -0.15201175 -0.24503904\n",
      "   0.50228065  0.51821743  0.42519013 -0.0565084  -0.04057162 -0.13359892\n",
      "   0.37965635  0.39559314  0.30256584  0.07484573  0.09078252 -0.00224478\n",
      "   0.24220143  0.25813822  0.16511092  0.21565028  0.23158706  0.13855976\n",
      "   0.10086546  0.11680225  0.02377495  0.35468883  0.37062561  0.27759831\n",
      "  -0.03309281 -0.01715603 -0.11018332  0.48088565  0.49682243  0.40379513\n",
      "  -0.14900235 -0.13306556 -0.22609286  0.58418797  0.60012476  0.50709746\n",
      "  -0.23762986 -0.22169308 -0.31472038  0.6563668   0.67230358  0.57927629\n",
      "  -0.29191534 -0.27597856 -0.36900585  0.6916724   0.70760919  0.61458189\n",
      "  -0.30753443 -0.29159765 -0.38462494  0.68729236  0.70322914  0.61020185\n",
      "  -0.28324292 -0.26730614 -0.36033344  0.64357558  0.65951237  0.56648507\n",
      "  -0.22097586 -0.20503908 -0.29806638  0.56400452  0.57994131  0.48691401\n",
      "  -0.12569342 -0.10975663 -0.20278393  0.45491777  0.47085455  0.37782725\n",
      "  -0.00498572  0.01095106 -0.08207624  0.3250051   0.34094189  0.24791459\n",
      "   0.13153171  0.14746849  0.0544412   0.1846153   0.20055208  0.10752478\n",
      "   0.27298398  0.28892077  0.19589347  0.04493172  0.06086851 -0.03215879\n",
      "   0.40810309  0.42403987  0.33101258 -0.0829185  -0.06698172 -0.16000902\n",
      "   0.52612552  0.5420623   0.449035   -0.18875091 -0.17281413 -0.26584143\n",
      "   0.61764967  0.63358645  0.54055915 -0.26413495 -0.24819817 -0.34122546\n",
      "   0.67538478  0.69132156  0.59829427 -0.30306557 -0.28712879 -0.38015608\n",
      "   0.69473171  0.71066849  0.6176412  -0.30244158 -0.2865048  -0.37953209\n",
      "   0.67414929  0.69008607  0.59705878 -0.26231268 -0.2463759  -0.3394032\n",
      "   0.6152771   0.63121389  0.53818659 -0.18587553 -0.16993875 -0.26296605\n",
      "   0.52280488  0.53874166  0.44571436 -0.07921906 -0.06328228 -0.15630958\n",
      "   0.40409889  0.42003567  0.32700838  0.04916053  0.06509732 -0.02792998\n",
      "   0.2686152   0.28455198  0.19152469  0.18903661  0.20497339  0.1119461\n",
      "   0.12714636  0.14308314  0.05005585  0.32926672  0.3452035   0.2521762\n",
      "  -0.00903831  0.00689847 -0.08612882  0.45868021  0.47461699  0.3815897\n",
      "  -0.12909041 -0.11315363 -0.20618092  0.56696808  0.58290486  0.48987756\n",
      "  -0.22344666 -0.20750988 -0.30053718  0.64550417  0.66144096  0.56841366\n",
      "  -0.2845907  -0.26865392 -0.36168122  0.68803236  0.70396914  0.61094185\n",
      "  -0.30765183 -0.29171505 -0.38474234  0.69116486  0.70710164  0.61407435\n",
      "  -0.29079301 -0.27485623 -0.36788352  0.65465215  0.67058893  0.57756163\n",
      "  -0.2353572  -0.21942042 -0.31244772  0.5814028   0.59733958  0.50431228\n",
      "  -0.1457604  -0.12982361 -0.22285091  0.47725181  0.4931886   0.4001613\n",
      "  -0.02913982 -0.01320304 -0.10623033  0.35049581  0.36643259  0.27340529\n",
      "   0.1052146   0.12115138  0.02812408  0.21123208  0.22716887  0.13414157\n",
      "   0.24660026  0.26253704  0.16950975  0.07055431  0.0864911  -0.0065362\n",
      "   0.38375447  0.39969125  0.30666396 -0.06033119 -0.04439441 -0.1374217\n",
      "   0.5057516   0.52168838  0.42866108 -0.17099817 -0.15506139 -0.24808868\n",
      "   0.60287342  0.61881021  0.52578291 -0.25263095 -0.23669417 -0.32972146\n",
      "   0.66738328  0.68332006  0.59029276 -0.29872671 -0.28278993 -0.37581723\n",
      "   0.69414234  0.71007913  0.61705183 -0.3056135  -0.28967671 -0.38270401\n",
      "  -0.42733592  0.97269017  0.27231118  0.          1.          2.2       ]]\n",
      "next state size: 306\n",
      "Next state: [[ 0.01972802  0.0356648  -0.05736249  0.43184651  0.44778329  0.35475599\n",
      "  -0.10472641 -0.08878963 -0.18181693  0.54556143  0.56149821  0.46847091\n",
      "  -0.20542582 -0.18948904 -0.28251633  0.63122982  0.6471666   0.55413931\n",
      "  -0.27434854 -0.25841176 -0.35143906  0.68202739  0.69796417  0.60493687\n",
      "  -0.30600424 -0.29006745 -0.38309475  0.69390762  0.70984441  0.61681711\n",
      "  -0.29787123 -0.28193445 -0.37496174  0.66592416  0.68186094  0.58883364\n",
      "  -0.25059739 -0.23466061 -0.32768791  0.60030613  0.61624292  0.52321562\n",
      "  -0.16794853 -0.15201175 -0.24503904  0.50228065  0.51821743  0.42519013\n",
      "  -0.0565084  -0.04057162 -0.13359892  0.37965635  0.39559314  0.30256584\n",
      "   0.07484573  0.09078252 -0.00224478  0.24220143  0.25813822  0.16511092\n",
      "   0.21565028  0.23158706  0.13855976  0.10086546  0.11680225  0.02377495\n",
      "   0.35468883  0.37062561  0.27759831 -0.03309281 -0.01715603 -0.11018332\n",
      "   0.48088565  0.49682243  0.40379513 -0.14900235 -0.13306556 -0.22609286\n",
      "   0.58418797  0.60012476  0.50709746 -0.23762986 -0.22169308 -0.31472038\n",
      "   0.6563668   0.67230358  0.57927629 -0.29191534 -0.27597856 -0.36900585\n",
      "   0.6916724   0.70760919  0.61458189 -0.30753443 -0.29159765 -0.38462494\n",
      "   0.68729236  0.70322914  0.61020185 -0.28324292 -0.26730614 -0.36033344\n",
      "   0.64357558  0.65951237  0.56648507 -0.22097586 -0.20503908 -0.29806638\n",
      "   0.56400452  0.57994131  0.48691401 -0.12569342 -0.10975663 -0.20278393\n",
      "   0.45491777  0.47085455  0.37782725 -0.00498572  0.01095106 -0.08207624\n",
      "   0.3250051   0.34094189  0.24791459  0.13153171  0.14746849  0.0544412\n",
      "   0.1846153   0.20055208  0.10752478  0.27298398  0.28892077  0.19589347\n",
      "   0.04493172  0.06086851 -0.03215879  0.40810309  0.42403987  0.33101258\n",
      "  -0.0829185  -0.06698172 -0.16000902  0.52612552  0.5420623   0.449035\n",
      "  -0.18875091 -0.17281413 -0.26584143  0.61764967  0.63358645  0.54055915\n",
      "  -0.26413495 -0.24819817 -0.34122546  0.67538478  0.69132156  0.59829427\n",
      "  -0.30306557 -0.28712879 -0.38015608  0.69473171  0.71066849  0.6176412\n",
      "  -0.30244158 -0.2865048  -0.37953209  0.67414929  0.69008607  0.59705878\n",
      "  -0.26231268 -0.2463759  -0.3394032   0.6152771   0.63121389  0.53818659\n",
      "  -0.18587553 -0.16993875 -0.26296605  0.52280488  0.53874166  0.44571436\n",
      "  -0.07921906 -0.06328228 -0.15630958  0.40409889  0.42003567  0.32700838\n",
      "   0.04916053  0.06509732 -0.02792998  0.2686152   0.28455198  0.19152469\n",
      "   0.18903661  0.20497339  0.1119461   0.12714636  0.14308314  0.05005585\n",
      "   0.32926672  0.3452035   0.2521762  -0.00903831  0.00689847 -0.08612882\n",
      "   0.45868021  0.47461699  0.3815897  -0.12909041 -0.11315363 -0.20618092\n",
      "   0.56696808  0.58290486  0.48987756 -0.22344666 -0.20750988 -0.30053718\n",
      "   0.64550417  0.66144096  0.56841366 -0.2845907  -0.26865392 -0.36168122\n",
      "   0.68803236  0.70396914  0.61094185 -0.30765183 -0.29171505 -0.38474234\n",
      "   0.69116486  0.70710164  0.61407435 -0.29079301 -0.27485623 -0.36788352\n",
      "   0.65465215  0.67058893  0.57756163 -0.2353572  -0.21942042 -0.31244772\n",
      "   0.5814028   0.59733958  0.50431228 -0.1457604  -0.12982361 -0.22285091\n",
      "   0.47725181  0.4931886   0.4001613  -0.02913982 -0.01320304 -0.10623033\n",
      "   0.35049581  0.36643259  0.27340529  0.1052146   0.12115138  0.02812408\n",
      "   0.21123208  0.22716887  0.13414157  0.24660026  0.26253704  0.16950975\n",
      "   0.07055431  0.0864911  -0.0065362   0.38375447  0.39969125  0.30666396\n",
      "  -0.06033119 -0.04439441 -0.1374217   0.5057516   0.52168838  0.42866108\n",
      "  -0.17099817 -0.15506139 -0.24808868  0.60287342  0.61881021  0.52578291\n",
      "  -0.25263095 -0.23669417 -0.32972146  0.66738328  0.68332006  0.59029276\n",
      "  -0.29872671 -0.28278993 -0.37581723  0.69414234  0.71007913  0.61705183\n",
      "  -0.3056135  -0.28967671 -0.38270401 -0.30897349  0.66158719 -1.87573093\n",
      "  -0.46086657  0.86007041  0.16972768  0.          1.          2.2       ]]\n",
      "Reward: -6.326210721395564\n",
      "Model output: tensor([[-0.1007, -0.1862, -0.1348]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Set up device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define the model with specific input, hidden, and output sizes\n",
    "input_size = 306  # Example: 102 measurements * 3 features\n",
    "hidden_size = 128\n",
    "output_size = 3  # Assuming the output is a 3-dimensional vector\n",
    "\n",
    "model = SimpleModel(input_size, hidden_size, output_size).to(device)\n",
    "\n",
    "class MyCustomEnv(gym.Env):\n",
    "    def __init__(self, model, device):\n",
    "        super(MyCustomEnv, self).__init__()\n",
    "        \n",
    "        self.modelt = modelt\n",
    "        self.device = device\n",
    "        \n",
    "        self.optimal_state = np.array([0, 1, 2.2])\n",
    "        self.df_1550 = []\n",
    "        self.t = 0\n",
    "        \n",
    "        # Action space: assuming a 3-dimensional continuous action space\n",
    "        self.action_space = spaces.Box(low=-2.0, high=2.0, shape=(3,), dtype=np.float32)\n",
    "        \n",
    "        # Observation space: for simplicity, let's assume it's a 100x3 array concatenated with two additional vectors\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(102, 3), dtype=np.float32)\n",
    "        \n",
    "        # Variables for after the action executes\n",
    "        self.measured_1550 = None\n",
    "        self.measured_1350= None\n",
    "        self.drifted_1550= None\n",
    "        self.drifted_1350=None\n",
    "        \n",
    "    def reset(self):\n",
    "        self.t = 0\n",
    "        action = np.array([0,0,0])\n",
    "        self.measured_1350 = np.array(DummyHardware.measure(1350, self.t))\n",
    "        self.data_to_correct_for = self.optimal_state - self.measured_1350\n",
    "        action = self.data_to_correct_for\n",
    "        self.measured_1550 = np.random.uniform(-2, 2, 3)\n",
    "        \n",
    "        self.df_1550 = []\n",
    "        while len(self.df_1550) < 100:\n",
    "            measured_1350 = copy.deepcopy(self.measured_1350)\n",
    "            measured_1550 = copy.deepcopy(self.measured_1550)\n",
    "            self.t += 1\n",
    "            self.measured_1350, self.measured_1550 = DummyHardware.implement(action, self.t, measured_1350, measured_1550)\n",
    "            self.df_1550.append(copy.deepcopy(self.measured_1550))\n",
    "        if len(self.df_1550) > 100:\n",
    "            self.df_1550.pop(0)\n",
    "        \n",
    "        stacked_df = np.stack(self.df_1550)\n",
    "        optimal_state_reshaped = self.optimal_state.reshape(1, -1)\n",
    "        stacked_df_with_optimal = np.concatenate((stacked_df, optimal_state_reshaped), axis=0)\n",
    "        tensor_df = torch.tensor(stacked_df_with_optimal, dtype=torch.float32).to(self.device)\n",
    "        output, _ = self.modelt(tensor_df, None)\n",
    "        next_state_measurements = np.array(self.df_1550)\n",
    "        output_numpy = output.cpu().detach().numpy().reshape(1, -1)\n",
    "        state = np.concatenate((next_state_measurements, output_numpy, optimal_state_reshaped), axis=0).reshape(1, -1)\n",
    "        print(\"state size:\", state.size)\n",
    "        return state\n",
    "    \n",
    "    def step(self, action):\n",
    "        measured_1350 = copy.deepcopy(self.measured_1350)\n",
    "        measured_1550 = copy.deepcopy(self.measured_1550)\n",
    "        self.t += 1\n",
    "        self.measured_1350, self.measured_1550 = DummyHardware.implement(action, self.t, measured_1350, measured_1550)\n",
    "        self.df_1550.append(copy.deepcopy(self.measured_1550))\n",
    "        if len(self.df_1550) > 100:\n",
    "            self.df_1550.pop(0)\n",
    "        \n",
    "        stacked_df = np.stack(self.df_1550)\n",
    "        optimal_state_reshaped = self.optimal_state.reshape(1, -1)\n",
    "        stacked_df_with_optimal = np.concatenate((stacked_df, optimal_state_reshaped), axis=0)\n",
    "        tensor_df = torch.tensor(stacked_df_with_optimal, dtype=torch.float32).to(self.device)\n",
    "        output, _ = self.modelt(tensor_df, None)\n",
    "        next_state_measurements = np.array(self.df_1550)\n",
    "        output_numpy = output.cpu().detach().numpy().reshape(1, -1)\n",
    "        next_state = np.concatenate((next_state_measurements, output_numpy, optimal_state_reshaped), axis=0).reshape(1, -1)\n",
    "        \n",
    "        reward = -np.mean((self.measured_1350 - self.optimal_state) ** 2)\n",
    "        \n",
    "        done = False  # You can implement logic for termination here if needed\n",
    "        info = {}  # Additional information for debugging\n",
    "        print(\"next state size:\", next_state.size)\n",
    "        return next_state, reward, done, info\n",
    "    \n",
    "    def render(self, mode='human'):\n",
    "        print(f\"t = {self.t}, Measured 1350: {self.measured_1350}, Measured 1550: {self.measured_1550}\")\n",
    "    \n",
    "    def close(self):\n",
    "        pass\n",
    "\n",
    "env = MyCustomEnv(model=modelt, device=device)\n",
    "state = env.reset()\n",
    "print(f\"Initial state: {state}\")\n",
    "\n",
    "action = np.array([1, -0.5, 2])  # Example action\n",
    "next_state, reward, done, info = env.step(action)\n",
    "print(f\"Next state: {next_state}\")\n",
    "print(f\"Reward: {reward}\")\n",
    "\n",
    "# Output result\n",
    "print(\"Model output:\", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6845d06e-4d5f-4d07-9e90-2a1fb3432333",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
