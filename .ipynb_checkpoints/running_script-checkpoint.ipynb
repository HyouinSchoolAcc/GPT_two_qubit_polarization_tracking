{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63de5bf8-7e51-4875-8791-b45b4b86cfe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of           TimeStamps       AI0       AI1       AI2       AI3       AI4  \\\n",
      "0           0.000000  2.229548  0.295483 -1.081807  1.623932 -1.120879   \n",
      "1           0.101122  2.219780  0.295483 -1.101343  1.633699 -1.101343   \n",
      "2           0.203640  2.210012  0.285714 -1.081807  1.643468 -1.081807   \n",
      "3           0.300221  2.219780  0.305250 -1.101343  1.653235 -1.072039   \n",
      "4           0.403315  2.200244  0.315019 -1.101343  1.653235 -1.062271   \n",
      "...              ...       ...       ...       ...       ...       ...   \n",
      "711710  71171.002492 -0.964591 -2.029304 -1.062271 -0.925519  0.686203   \n",
      "711711  71171.100106 -0.876678 -2.078144 -1.013431 -0.915751  0.676435   \n",
      "711712  71171.201757 -0.759462 -2.136752 -0.993895 -0.896214  0.637362   \n",
      "711713  71171.303305 -0.769231 -2.126984 -1.032967 -0.827839  0.656898   \n",
      "711714  71171.401576 -0.769231 -2.146520 -0.896214 -0.905983  0.520146   \n",
      "\n",
      "             AI5  \n",
      "0      -1.492064  \n",
      "1      -1.501831  \n",
      "2      -1.501831  \n",
      "3      -1.492064  \n",
      "4      -1.492064  \n",
      "...          ...  \n",
      "711710 -2.185592  \n",
      "711711 -2.185592  \n",
      "711712 -2.214896  \n",
      "711713 -2.205128  \n",
      "711714 -2.214896  \n",
      "\n",
      "[711715 rows x 7 columns]>\n",
      "step 0: train loss 2.5698, val loss 3.4719\n",
      "step 1: train loss 1.5807, val loss 2.6831\n",
      "step 2: train loss 0.9822, val loss 1.8376\n",
      "step 3: train loss 0.7088, val loss 1.4409\n",
      "step 4: train loss 0.6879, val loss 1.3795\n",
      "step 5: train loss 0.7015, val loss 1.1587\n",
      "step 6: train loss 0.6501, val loss 0.9538\n",
      "step 7: train loss 0.6129, val loss 0.6212\n",
      "step 8: train loss 0.5860, val loss 0.3831\n",
      "step 9: train loss 0.5066, val loss 0.2204\n",
      "step 10: train loss 0.3583, val loss 0.1858\n",
      "step 11: train loss 0.3349, val loss 0.2796\n",
      "step 12: train loss 0.3468, val loss 0.4484\n",
      "step 13: train loss 0.3591, val loss 0.5502\n",
      "step 14: train loss 0.3511, val loss 0.5378\n",
      "step 15: train loss 0.3433, val loss 0.5035\n",
      "step 16: train loss 0.3731, val loss 0.4201\n",
      "step 17: train loss 0.3864, val loss 0.3091\n",
      "step 18: train loss 0.3599, val loss 0.2108\n",
      "step 19: train loss 0.3309, val loss 0.1411\n",
      "step 20: train loss 0.2884, val loss 0.1008\n",
      "step 21: train loss 0.2585, val loss 0.0707\n",
      "step 22: train loss 0.2314, val loss 0.0527\n",
      "step 23: train loss 0.2315, val loss 0.0390\n",
      "step 24: train loss 0.2428, val loss 0.0306\n",
      "step 25: train loss 0.2411, val loss 0.0299\n",
      "step 26: train loss 0.2382, val loss 0.0397\n",
      "step 27: train loss 0.2628, val loss 0.0518\n",
      "step 28: train loss 0.2498, val loss 0.0660\n",
      "step 29: train loss 0.2604, val loss 0.0803\n",
      "step 30: train loss 0.2650, val loss 0.0996\n",
      "step 31: train loss 0.2474, val loss 0.1324\n",
      "step 32: train loss 0.2339, val loss 0.1757\n",
      "step 33: train loss 0.2392, val loss 0.2262\n",
      "step 34: train loss 0.2289, val loss 0.2717\n",
      "step 35: train loss 0.2351, val loss 0.3062\n",
      "step 36: train loss 0.2439, val loss 0.3460\n",
      "step 37: train loss 0.2528, val loss 0.3592\n",
      "step 38: train loss 0.2551, val loss 0.3685\n",
      "step 39: train loss 0.2495, val loss 0.3508\n",
      "step 40: train loss 0.2360, val loss 0.3083\n",
      "step 41: train loss 0.2394, val loss 0.2514\n",
      "step 42: train loss 0.2175, val loss 0.2172\n",
      "step 43: train loss 0.2078, val loss 0.1833\n",
      "step 44: train loss 0.1823, val loss 0.1370\n",
      "step 45: train loss 0.1729, val loss 0.1076\n",
      "step 46: train loss 0.1628, val loss 0.0766\n",
      "step 47: train loss 0.1637, val loss 0.0546\n",
      "step 48: train loss 0.1705, val loss 0.0486\n",
      "step 49: train loss 0.1672, val loss 0.0453\n",
      "step 50: train loss 0.1598, val loss 0.0346\n",
      "step 51: train loss 0.1602, val loss 0.0317\n",
      "step 52: train loss 0.1678, val loss 0.0311\n",
      "step 53: train loss 0.1561, val loss 0.0288\n",
      "step 54: train loss 0.1644, val loss 0.0274\n",
      "step 55: train loss 0.1478, val loss 0.0287\n",
      "step 56: train loss 0.1535, val loss 0.0278\n",
      "step 57: train loss 0.1424, val loss 0.0262\n",
      "step 58: train loss 0.1506, val loss 0.0267\n",
      "step 59: train loss 0.1675, val loss 0.0272\n",
      "step 60: train loss 0.1740, val loss 0.0261\n",
      "step 61: train loss 0.1899, val loss 0.0250\n",
      "step 62: train loss 0.1739, val loss 0.0261\n",
      "step 63: train loss 0.1735, val loss 0.0285\n",
      "step 64: train loss 0.1506, val loss 0.0430\n",
      "step 65: train loss 0.1427, val loss 0.0630\n",
      "step 66: train loss 0.1424, val loss 0.0731\n",
      "step 67: train loss 0.1528, val loss 0.0688\n",
      "step 68: train loss 0.1422, val loss 0.0685\n",
      "step 69: train loss 0.1393, val loss 0.0740\n",
      "step 70: train loss 0.1419, val loss 0.0793\n",
      "step 71: train loss 0.1270, val loss 0.0705\n",
      "step 72: train loss 0.1246, val loss 0.0613\n",
      "step 73: train loss 0.1337, val loss 0.0518\n",
      "step 74: train loss 0.1268, val loss 0.0378\n",
      "step 75: train loss 0.1236, val loss 0.0297\n",
      "step 76: train loss 0.1218, val loss 0.0273\n",
      "step 77: train loss 0.1271, val loss 0.0287\n",
      "step 78: train loss 0.1309, val loss 0.0343\n",
      "step 79: train loss 0.1289, val loss 0.0440\n",
      "step 80: train loss 0.1359, val loss 0.0389\n",
      "step 81: train loss 0.1327, val loss 0.0356\n",
      "step 82: train loss 0.1361, val loss 0.0336\n",
      "step 83: train loss 0.1448, val loss 0.0391\n",
      "step 84: train loss 0.1374, val loss 0.0421\n",
      "step 85: train loss 0.1394, val loss 0.0450\n",
      "step 86: train loss 0.1409, val loss 0.0425\n",
      "step 87: train loss 0.1411, val loss 0.0396\n",
      "step 88: train loss 0.1339, val loss 0.0409\n",
      "step 89: train loss 0.1446, val loss 0.0329\n",
      "step 90: train loss 0.1322, val loss 0.0280\n",
      "step 91: train loss 0.1286, val loss 0.0261\n",
      "step 92: train loss 0.1266, val loss 0.0323\n",
      "step 93: train loss 0.1272, val loss 0.0393\n",
      "step 94: train loss 0.1183, val loss 0.0409\n",
      "step 95: train loss 0.1322, val loss 0.0401\n",
      "step 96: train loss 0.1392, val loss 0.0396\n",
      "step 97: train loss 0.1332, val loss 0.0377\n",
      "step 98: train loss 0.1260, val loss 0.0391\n",
      "step 99: train loss 0.1255, val loss 0.0451\n",
      "step 100: train loss 0.1384, val loss 0.0571\n",
      "step 101: train loss 0.1395, val loss 0.0627\n",
      "step 102: train loss 0.1314, val loss 0.0507\n",
      "step 103: train loss 0.1259, val loss 0.0449\n",
      "step 104: train loss 0.1277, val loss 0.0480\n",
      "step 105: train loss 0.1524, val loss 0.0513\n",
      "step 106: train loss 0.1499, val loss 0.0548\n",
      "step 107: train loss 0.1373, val loss 0.0464\n",
      "step 108: train loss 0.1333, val loss 0.0332\n",
      "step 109: train loss 0.1226, val loss 0.0248\n",
      "step 110: train loss 0.1236, val loss 0.0255\n",
      "step 111: train loss 0.1162, val loss 0.0246\n",
      "step 112: train loss 0.1146, val loss 0.0232\n",
      "step 113: train loss 0.1195, val loss 0.0272\n",
      "step 114: train loss 0.1206, val loss 0.0293\n",
      "step 115: train loss 0.1152, val loss 0.0324\n",
      "step 116: train loss 0.1183, val loss 0.0319\n",
      "step 117: train loss 0.1254, val loss 0.0328\n",
      "step 118: train loss 0.1217, val loss 0.0319\n",
      "step 119: train loss 0.1120, val loss 0.0292\n",
      "step 120: train loss 0.1250, val loss 0.0265\n",
      "step 121: train loss 0.1195, val loss 0.0261\n",
      "step 122: train loss 0.1167, val loss 0.0251\n",
      "step 123: train loss 0.1073, val loss 0.0246\n",
      "step 124: train loss 0.1115, val loss 0.0248\n",
      "step 125: train loss 0.1092, val loss 0.0285\n",
      "step 126: train loss 0.1127, val loss 0.0316\n",
      "step 127: train loss 0.1100, val loss 0.0373\n",
      "step 128: train loss 0.1130, val loss 0.0419\n",
      "step 129: train loss 0.1153, val loss 0.0424\n",
      "step 130: train loss 0.1145, val loss 0.0406\n",
      "step 131: train loss 0.1106, val loss 0.0458\n",
      "step 132: train loss 0.1129, val loss 0.0444\n",
      "step 133: train loss 0.1100, val loss 0.0444\n",
      "step 134: train loss 0.1092, val loss 0.0447\n",
      "step 135: train loss 0.1032, val loss 0.0387\n",
      "step 136: train loss 0.1038, val loss 0.0378\n",
      "step 137: train loss 0.1078, val loss 0.0451\n",
      "step 138: train loss 0.1290, val loss 0.0619\n",
      "step 139: train loss 0.1389, val loss 0.0588\n",
      "step 140: train loss 0.1104, val loss 0.0455\n",
      "step 141: train loss 0.1035, val loss 0.0341\n",
      "step 142: train loss 0.1031, val loss 0.0339\n",
      "step 143: train loss 0.1077, val loss 0.0425\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'loss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 245\u001b[0m\n\u001b[0;32m    243\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m xb, yb, predictions, loss  \u001b[38;5;66;03m# Assuming these are not needed after the training step\u001b[39;00m\n\u001b[0;32m    244\u001b[0m     clean_memory()  \u001b[38;5;66;03m# Call this to clear memory\u001b[39;00m\n\u001b[1;32m--> 245\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoss:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mloss\u001b[49m\u001b[38;5;241m.\u001b[39mitem())\n",
      "\u001b[1;31mNameError\u001b[0m: name 'loss' is not defined"
     ]
    }
   ],
   "source": [
    "#import some stuff\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import math\n",
    "from scipy.optimize import minimize\n",
    "from scipy.interpolate import CubicSpline\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import gc\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "def clean_memory():\n",
    "    gc.collect()           # Garbage collect Python objects\n",
    "    torch.cuda.empty_cache()  # Clear cached memory on GPU\n",
    "\n",
    "\n",
    "data_dir = \"C:/Users/凤凰院凶真/Desktop/GPT_two_qubit_polarization_tracking/20240506_2131.csv\"\n",
    "df = pd.read_csv(data_dir)\n",
    "print(df.head)\n",
    "\n",
    "features = [\"AI0\",\"AI1\",\"AI2\"]\n",
    "targets  = [\"AI3\",\"AI4\",\"AI5\"]\n",
    "x = df[features]  # Dropping original targets as we'll use aligned targets\n",
    "y = df[targets]  # Using aligned targets\n",
    "split_idx = int(len(df) * 0.9)\n",
    "length_read=len(df)\n",
    "# Split into training and testing sets\n",
    "x_train = x.iloc[:split_idx]\n",
    "y_train = y.iloc[:split_idx]\n",
    "x_test = x.iloc[split_idx:]\n",
    "y_test = y.iloc[split_idx:]\n",
    "\n",
    "input_feature_dim = 3  # Each input element is a 1x3 vector\n",
    "embed_size = 64\n",
    "target_dim = 3\n",
    "block_size = 40\n",
    "num_heads = 16\n",
    "max_iters = 144\n",
    "batch_size = 10\n",
    "eval_iters = 200\n",
    "eval_interval = 1\n",
    "num_layers=5\n",
    "\n",
    "def get_batch3(split):\n",
    "    # Select the correct data split\n",
    "    if split == 'train':\n",
    "        a, b, max_index = x_train, y_train, int(length_read * 0.9) - block_size - 1\n",
    "    else:  # split == 'test'\n",
    "        a, b, max_index = x_test, y_test, length_read - (int(length_read * 0.9) + block_size + 1)\n",
    "\n",
    "    # Generate random indices for batch selection, ensuring they're within bounds\n",
    "    ix = torch.randint(0, max_index, (batch_size,))\n",
    "\n",
    "    # Initialize lists to hold the batches\n",
    "    x_batch = []\n",
    "    y_batch = []\n",
    "\n",
    "    for i in ix:\n",
    "        try:\n",
    "                        # Extract the sequence from 'a' and the corresponding target from 'b'                                                           \n",
    "            seq = torch.tensor(a.iloc[i.item():i.item() + block_size].astype(np.float32).values, dtype=torch.float32)\n",
    "            target = torch.tensor(b.iloc[i.item() + block_size].astype(np.float32).values, dtype=torch.float32)\n",
    "\n",
    "            x_batch.append(seq)\n",
    "            y_batch.append(target)\n",
    "        except IndexError as e:\n",
    "            print(f\"IndexError for index {i.item()}: {str(e)}\")\n",
    "            print(f\"Attempting to access index [{i.item()}:{i.item() + block_size}] in 'a' with shape {a.shape}\")\n",
    "            print(f\"Attempting to access index {i.item() + block_size} in 'b' with shape {b.shape}\")\n",
    "            # Optionally, break or continue depending on desired behavior on error\n",
    "            break  # or continue\n",
    "\n",
    "    if not x_batch or not y_batch:\n",
    "        print(\"Error: Batch could not be created due to index issues.\")\n",
    "        return None, None\n",
    "\n",
    "    # Stack the collected sequences and targets into tensors\n",
    "    xstack = torch.stack(x_batch)\n",
    "    ystack = torch.stack(y_batch)\n",
    "\n",
    "    return xstack, ystack\n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, embed_size):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.embed_size = embed_size\n",
    "\n",
    "        self.keys = nn.Linear(embed_size, embed_size, bias=False)\n",
    "        self.queries = nn.Linear(embed_size, embed_size, bias=False)\n",
    "        self.values = nn.Linear(embed_size, embed_size, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        K = self.keys(x)\n",
    "        Q = self.queries(x)\n",
    "        V = self.values(x)\n",
    "\n",
    "        attention_scores = torch.matmul(Q, K.transpose(-2, -1)) / self.embed_size ** 0.5\n",
    "        attention = torch.softmax(attention_scores, dim=-1)\n",
    "\n",
    "        attended = torch.matmul(attention, V)\n",
    "        return attended\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, embed_size, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.embed_size = embed_size\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "        assert embed_size % num_heads == 0\n",
    "\n",
    "        self.head_dim = embed_size // num_heads\n",
    "\n",
    "        self.keys = nn.Linear(embed_size, embed_size, bias=False)\n",
    "        self.queries = nn.Linear(embed_size, embed_size, bias=False)\n",
    "        self.values = nn.Linear(embed_size, embed_size, bias=False)\n",
    "\n",
    "        self.fc_out = nn.Linear(embed_size, embed_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, seq_length, _ = x.shape\n",
    "\n",
    "        keys = self.keys(x).view(batch_size, seq_length, self.num_heads, self.head_dim)\n",
    "        queries = self.queries(x).view(batch_size, seq_length, self.num_heads, self.head_dim)\n",
    "        values = self.values(x).view(batch_size, seq_length, self.num_heads, self.head_dim)\n",
    "\n",
    "        attention_scores = torch.einsum(\"bnqh,bnkh->bnqk\", [queries, keys]) / (self.head_dim ** 0.5)\n",
    "        attention = torch.softmax(attention_scores, dim=-1)\n",
    "\n",
    "        attended = torch.einsum(\"bnqk,bnkv->bnqv\", [attention, values]).reshape(batch_size, seq_length, self.embed_size)\n",
    "\n",
    "        output = self.fc_out(attended)\n",
    "        return output\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch3(split)\n",
    "            X, Y = X.to(device), Y.to(device)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train\n",
    "    del X, Y\n",
    "    return out\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, embed_size, num_heads):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.norm1 = nn.LayerNorm(embed_size)\n",
    "        self.attention = MultiHeadAttention(embed_size, num_heads)\n",
    "        self.dropout1 = nn.Dropout(0.1)\n",
    "\n",
    "        self.norm2 = nn.LayerNorm(embed_size)\n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(embed_size, 2 * embed_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2 * embed_size, embed_size),\n",
    "        )\n",
    "        self.dropout2 = nn.Dropout(0.1)\n",
    "\n",
    "    def forward(self, value):\n",
    "        x = self.norm1(value)\n",
    "        attention_output = self.attention(x)\n",
    "        x = value + self.dropout1(attention_output)  # Residual connection and dropout after attention\n",
    "        x = self.norm2(x)\n",
    "        feed_forward_output = self.feed_forward(x)\n",
    "        out = value + self.dropout2(feed_forward_output)  # Residual connection and dropout after FFN\n",
    "        return out\n",
    "\n",
    "# Positional Encoding in Encoder class should be moved to the device\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_feature_dim, embed_size, num_heads, num_layers, seq_length):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.input_fc = nn.Linear(input_feature_dim, embed_size)\n",
    "        self.positional_encoding = nn.Parameter(torch.randn(1, seq_length, embed_size)).to(device)\n",
    "        self.layers = nn.ModuleList([\n",
    "            TransformerBlock(embed_size, num_heads) for _ in range(num_layers)])\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.input_fc(x)) + self.positional_encoding\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "class EncoderDecoderModelWithMultiHeadAttention(nn.Module):\n",
    "    def __init__(self, input_feature_dim, embed_size, target_dim, seq_length, num_heads, num_layers):\n",
    "        super(EncoderDecoderModelWithMultiHeadAttention, self).__init__()\n",
    "        self.encoder = Encoder(input_feature_dim, embed_size, num_heads, num_layers, seq_length)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(embed_size, target_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, targets):\n",
    "        encoded = self.encoder(x)\n",
    "        encoded_pooled = torch.mean(encoded, dim=1)\n",
    "        decoded = self.decoder(encoded_pooled)\n",
    "        \n",
    "        if targets is not None:\n",
    "            loss = criterion(decoded, targets)  \n",
    "            return decoded, loss\n",
    "\n",
    "\n",
    "        return decoded, loss\n",
    "    \n",
    "\n",
    "\n",
    "actuals = []\n",
    "predictions = []\n",
    "if __name__ == \"__main__\":\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    model = EncoderDecoderModelWithMultiHeadAttention(input_feature_dim, embed_size, target_dim, block_size, num_heads, num_layers).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    for iter in range(max_iters):\n",
    "        # Evaluate the loss periodically\n",
    "        if iter % eval_interval == 0 or iter == max_iters - 1:\n",
    "            losses = estimate_loss()\n",
    "            print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "\n",
    "        xb, yb = get_batch3('train')\n",
    "        xb, yb = xb.to(device), yb.to(device)  # Ensure these tensors are on the correct device\n",
    "\n",
    "        predictions, loss = model(xb, yb)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "                # After using tensors in a training step\n",
    "        del xb, yb, predictions  # Assuming these are not needed after the training step\n",
    "        clean_memory()  # Call this to clear memoryq\n",
    "    print(\"Loss:\", loss.item())\n",
    "    del xb, yb, predictions  # Assuming these are not needed after the training step\n",
    "    clean_memory()  # Call this to clear memoryq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465ed6d1-7c47-428a-9113-160cd598a1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.eval\n",
    "def prepare_full_dataset(x, block_size, device):\n",
    "    full_sequences = []\n",
    "    for i in range(len(x) - block_size):\n",
    "        seq = torch.tensor(x.iloc[i:i + block_size].astype(np.float32).values, device=device)\n",
    "        full_sequences.append(seq)\n",
    "    \n",
    "    full_dataset = torch.stack(full_sequences)\n",
    "    return full_dataset\n",
    "\n",
    "# Prepare the full dataset and send it to the correct device\n",
    "x_full = prepare_full_dataset(df[features], block_size, device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6100fda4-c5ca-43c9-94cc-2d770a917c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    total_cached = torch.cuda.memory_reserved(device)  # Total memory reserved (allocated + cached)\n",
    "    total_allocated = torch.cuda.memory_allocated(device)  # Total memory allocated\n",
    "    total_cached_free = total_cached - total_allocated  # Cached (free) memory\n",
    "\n",
    "    print(f\"Total Cached Memory: {total_cached / 1024**3:.3f} GB\")\n",
    "    print(f\"Total Allocated Memory: {total_allocated / 1024**3:.3f} GB\")\n",
    "    print(f\"Total Cached (Free) Memory: {total_cached_free / 1024**3:.3f} GB\")\n",
    "else:\n",
    "    print(\"CUDA is not available. No GPU detected.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8cfbd4e7-87db-49a8-a2da-4572afb65846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 2.2295,  0.2955, -1.0818],\n",
      "         [ 2.2198,  0.2955, -1.1013],\n",
      "         [ 2.2100,  0.2857, -1.0818],\n",
      "         ...,\n",
      "         [ 0.3639, -1.9219,  1.1551],\n",
      "         [ 2.3956, -0.2515, -0.2711],\n",
      "         [ 2.1123,  1.0867, -1.1013]],\n",
      "\n",
      "        [[ 2.2198,  0.2955, -1.1013],\n",
      "         [ 2.2100,  0.2857, -1.0818],\n",
      "         [ 2.2198,  0.3053, -1.1013],\n",
      "         ...,\n",
      "         [ 2.3956, -0.2515, -0.2711],\n",
      "         [ 2.1123,  1.0867, -1.1013],\n",
      "         [ 0.7155,  2.4444,  0.2271]],\n",
      "\n",
      "        [[ 2.2100,  0.2857, -1.0818],\n",
      "         [ 2.2198,  0.3053, -1.1013],\n",
      "         [ 2.2002,  0.3150, -1.1013],\n",
      "         ...,\n",
      "         [ 2.1123,  1.0867, -1.1013],\n",
      "         [ 0.7155,  2.4444,  0.2271],\n",
      "         [-0.9548,  2.2784,  0.0611]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 2.2002,  0.2857, -1.0916],\n",
      "         [ 2.2002,  0.3346, -1.1306],\n",
      "         [ 2.2002,  0.3248, -1.1013],\n",
      "         ...,\n",
      "         [-0.1148,  2.2491, -1.1013],\n",
      "         [ 1.9365,  1.3602, -0.4762],\n",
      "         [ 2.4249, -0.6129,  0.0806]],\n",
      "\n",
      "        [[ 2.2002,  0.3346, -1.1306],\n",
      "         [ 2.2002,  0.3248, -1.1013],\n",
      "         [ 2.2002,  0.3248, -1.1209],\n",
      "         ...,\n",
      "         [ 1.9365,  1.3602, -0.4762],\n",
      "         [ 2.4249, -0.6129,  0.0806],\n",
      "         [ 1.3797, -1.9902,  1.2625]],\n",
      "\n",
      "        [[ 2.2002,  0.3248, -1.1013],\n",
      "         [ 2.2002,  0.3248, -1.1209],\n",
      "         [ 2.2002,  0.3150, -1.1209],\n",
      "         ...,\n",
      "         [ 2.4249, -0.6129,  0.0806],\n",
      "         [ 1.3797, -1.9902,  1.2625],\n",
      "         [-1.1600, -0.7106,  1.8584]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print (x_full[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66823643-9750-4c67-b694-acd5fb4b5bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class EncoderDecoderModelWithMultiHeadAttention(nn.Module):\n",
    "    def __init__(self, input_feature_dim, embed_size, target_dim, seq_length, num_heads, num_layers):\n",
    "        super(EncoderDecoderModelWithMultiHeadAttention, self).__init__()\n",
    "        self.encoder = Encoder(input_feature_dim, embed_size, num_heads, num_layers, seq_length)\n",
    "        self.decoder = nn.Sequential(nn.Linear(embed_size, target_dim))\n",
    "\n",
    "    def forward(self, x, targets=None):\n",
    "        \n",
    "        encoded = self.encoder(x)\n",
    "        encoded_pooled = torch.mean(encoded, dim=1)\n",
    "        decoded = self.decoder(encoded_pooled)\n",
    "        \n",
    "        if targets is not None:\n",
    "            loss = torch.nn.functional.mse_loss(decoded, targets)  # Assuming MSE Loss\n",
    "            return decoded, loss\n",
    "        return decoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2b7a6779-c019-4a7d-9e4d-3d17af193d47",
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 110.00 MiB. GPU 0 has a total capacty of 8.00 GiB of which 0 bytes is free. Of the allocated memory 14.02 GiB is allocated by PyTorch, and 12.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m----> 2\u001b[0m     predictions_full \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_full\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Assuming x_full is the tensor from the prepare_full_dataset function\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Convert predictions to a suitable format if necessary\u001b[39;00m\n\u001b[0;32m      5\u001b[0m predictions_full \u001b[38;5;241m=\u001b[39m predictions_full\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[21], line 209\u001b[0m, in \u001b[0;36mEncoderDecoderModelWithMultiHeadAttention.forward\u001b[1;34m(self, x, targets)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, targets):\n\u001b[1;32m--> 209\u001b[0m     encoded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    210\u001b[0m     encoded_pooled \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean(encoded, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    211\u001b[0m     decoded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(encoded_pooled)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[21], line 197\u001b[0m, in \u001b[0;36mEncoder.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    195\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_fc(x)) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositional_encoding\n\u001b[0;32m    196\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m--> 197\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[21], line 176\u001b[0m, in \u001b[0;36mTransformerBlock.forward\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, value):\n\u001b[1;32m--> 176\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    177\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattention(x)\n\u001b[0;32m    178\u001b[0m     x \u001b[38;5;241m=\u001b[39m value \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout1(attention_output)  \u001b[38;5;66;03m# Residual connection and dropout after attention\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\normalization.py:196\u001b[0m, in \u001b[0;36mLayerNorm.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 196\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalized_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\functional.py:2543\u001b[0m, in \u001b[0;36mlayer_norm\u001b[1;34m(input, normalized_shape, weight, bias, eps)\u001b[0m\n\u001b[0;32m   2539\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_variadic(\u001b[38;5;28minput\u001b[39m, weight, bias):\n\u001b[0;32m   2540\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m   2541\u001b[0m         layer_norm, (\u001b[38;5;28minput\u001b[39m, weight, bias), \u001b[38;5;28minput\u001b[39m, normalized_shape, weight\u001b[38;5;241m=\u001b[39mweight, bias\u001b[38;5;241m=\u001b[39mbias, eps\u001b[38;5;241m=\u001b[39meps\n\u001b[0;32m   2542\u001b[0m     )\n\u001b[1;32m-> 2543\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalized_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 110.00 MiB. GPU 0 has a total capacty of 8.00 GiB of which 0 bytes is free. Of the allocated memory 14.02 GiB is allocated by PyTorch, and 12.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    predictions_full = model(x_full,None)  # Assuming x_full is the tensor from the prepare_full_dataset function\n",
    "\n",
    "# Convert predictions to a suitable format if necessary\n",
    "predictions_full = predictions_full.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8c24c667-eb8d-4ddd-9642-22fa7730afee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Cached Memory: 7.135 GB\n",
      "Total Allocated Memory: 7.124 GB\n",
      "Total Cached (Free) Memory: 0.011 GB\n"
     ]
    }
   ],
   "source": [
    "# Ensure CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    total_cached = torch.cuda.memory_reserved(device)  # Total memory reserved (allocated + cached)\n",
    "    total_allocated = torch.cuda.memory_allocated(device)  # Total memory allocated\n",
    "    total_cached_free = total_cached - total_allocated  # Cached (free) memory\n",
    "\n",
    "    print(f\"Total Cached Memory: {total_cached / 1024**3:.3f} GB\")\n",
    "    print(f\"Total Allocated Memory: {total_allocated / 1024**3:.3f} GB\")\n",
    "    print(f\"Total Cached (Free) Memory: {total_cached_free / 1024**3:.3f} GB\")\n",
    "else:\n",
    "    print(\"CUDA is not available. No GPU detected.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2c496103-6c44-4c0b-809f-7c1dba6b2537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 2            |        cudaMalloc retries: 3         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |   7294 MiB |  14354 MiB |   2270 GiB |   2263 GiB |\n",
      "|       from large pool |   7292 MiB |  14350 MiB |     54 GiB |     47 GiB |\n",
      "|       from small pool |      2 MiB |    350 MiB |   2215 GiB |   2215 GiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |   7294 MiB |  14354 MiB |   2270 GiB |   2263 GiB |\n",
      "|       from large pool |   7292 MiB |  14350 MiB |     54 GiB |     47 GiB |\n",
      "|       from small pool |      2 MiB |    350 MiB |   2215 GiB |   2215 GiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Requested memory      |   7294 MiB |  14353 MiB |   2267 GiB |   2260 GiB |\n",
      "|       from large pool |   7291 MiB |  14350 MiB |     54 GiB |     47 GiB |\n",
      "|       from small pool |      2 MiB |    328 MiB |   2212 GiB |   2212 GiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |   7306 MiB |  14368 MiB |  29006 MiB |  21700 MiB |\n",
      "|       from large pool |   7296 MiB |  14356 MiB |  28366 MiB |  21070 MiB |\n",
      "|       from small pool |     10 MiB |    352 MiB |    640 MiB |    630 MiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |  11428 KiB |  15480 KiB |   2219 GiB |   2219 GiB |\n",
      "|       from large pool |   3840 KiB |  12160 KiB |      0 GiB |      0 GiB |\n",
      "|       from small pool |   7588 KiB |   9430 KiB |   2219 GiB |   2219 GiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |     281    |  712028    |   22307 K  |   22306 K  |\n",
      "|       from large pool |       4    |       6    |       0 K  |       0 K  |\n",
      "|       from small pool |     277    |  712025    |   22307 K  |   22306 K  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |     281    |  712028    |   22307 K  |   22306 K  |\n",
      "|       from large pool |       4    |       6    |       0 K  |       0 K  |\n",
      "|       from small pool |     277    |  712025    |   22307 K  |   22306 K  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |       8    |     179    |     328    |     320    |\n",
      "|       from large pool |       3    |       5    |       8    |       5    |\n",
      "|       from small pool |       5    |     176    |     320    |     315    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |      34    |      54    |   12652 K  |   12652 K  |\n",
      "|       from large pool |       1    |       2    |       0 K  |       0 K  |\n",
      "|       from small pool |      33    |      53    |   12652 K  |   12652 K  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gc.collect()  # Collect garbage to free unreferenced memory\n",
    "torch.cuda.empty_cache()  # Clear unused memory from the cache\n",
    "\n",
    "# If you print the memory status here, you should see that the memory used by 'a' and 'b' is released\n",
    "print(torch.cuda.memory_summary())  # Detailed memory usage stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b16a65-a758-4f97-a037-a25d15d0afea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
