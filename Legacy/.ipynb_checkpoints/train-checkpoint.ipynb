{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37f9c59f-60cb-4d4c-b4d6-5fa28329c551",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yueze\\anaconda3\\Lib\\site-packages\\torch\\utils\\_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TDMS File Data Loaded:\n"
     ]
    }
   ],
   "source": [
    "#import some stuff\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import math\n",
    "from scipy.optimize import minimize\n",
    "from scipy.interpolate import CubicSpline\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import torch.optim as optim\n",
    "import gc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nptdms import TdmsFile\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "import matplotlib.pyplot as plt\n",
    "# Step 1: Load the .tdms file\n",
    "file_path = \"C:/Users/yueze/Downloads/20241126_1517.tdms\"\n",
    "tdms_file = TdmsFile.read(file_path)\n",
    "\n",
    "# Convert TDMS data to a pandas DataFrame\n",
    "df_tdms = tdms_file.as_dataframe()\n",
    "print(\"TDMS File Data Loaded:\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "def clean_memory():\n",
    "    gc.collect()           # Garbage collect Python objects\n",
    "    torch.cuda.empty_cache()  # Clear cached memory on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f057dd7e-ce5e-4b28-aa88-703a98a0645b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   /'Analog'/'AI0'  /'Analog'/'AI1'  /'Analog'/'AI2'  /'Analog'/'AI3'  \\\n",
      "0         2.483517         1.418804         0.100122         2.444445   \n",
      "1         2.473749         1.418804         0.109890         2.444445   \n",
      "2         2.483517         1.418804         0.090354         2.444445   \n",
      "3         2.483517         1.418804         0.061050         2.444445   \n",
      "4         2.483517         1.418804         0.109890         2.444445   \n",
      "\n",
      "   /'Analog'/'AI4'  /'Analog'/'AI5'  \n",
      "0         0.031746        -0.124542  \n",
      "1         0.041514        -0.095238  \n",
      "2         0.051282        -0.095238  \n",
      "3         0.041514        -0.095238  \n",
      "4         0.051282        -0.095238  \n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "# the origin of this data seems to be from july\n",
    "data_dir = \"C:/Users/yueze/Desktop/GPT_two_qubit_polarization_tracking/data_2.csv\"\n",
    "df = pd.read_csv(data_dir)\n",
    "print(df.head)\n",
    "'''\n",
    "\n",
    "print(df_tdms.head())  # Display the first few rows to verify the data structure\n",
    "df = df_tdms.iloc[::500]\n",
    "# Step 2: Define the features and target columns\n",
    "features = [\"/'Analog'/'AI3'\", \"/'Analog'/'AI4'\", \"/'Analog'/'AI5'\"]  # Feature column\n",
    "targets = [\"/'Analog'/'AI0'\", \"/'Analog'/'AI1'\", \"/'Analog'/'AI2'\"]  # Target columns\n",
    "'''\n",
    "targets = [\"AI0\",\"AI1\",\"AI2\"]\n",
    "features  = [\"AI3\",\"AI4\",\"AI5\"]\n",
    "'''\n",
    "x = df[features]  # Dropping original targets as we'll use aligned targets\n",
    "y = df[targets]  # Using aligned targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75e0878e-6a60-4609-884f-12031e83799c",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_idx = int(len(df) * 0.8)\n",
    "length_read=len(df)\n",
    "# Split into training and testing sets\n",
    "x_train = x.iloc[:split_idx]\n",
    "y_train = y.iloc[:split_idx]\n",
    "x_test = x.iloc[split_idx:]\n",
    "y_test = y.iloc[split_idx:]\n",
    "\n",
    "input_feature_dim = 3  # Each input element is a 1x3 vector\n",
    "embed_size = 128\n",
    "target_dim = 3\n",
    "block_size = 100\n",
    "num_heads = 32\n",
    "max_iters = 1500\n",
    "batch_size = 32\n",
    "eval_iters = 200\n",
    "eval_interval = 10\n",
    "num_layers=12\n",
    "\n",
    "def get_batch3(split):\n",
    "    # Select the correct data split\n",
    "    if split == 'train':\n",
    "        a, b, max_index = x_train, y_train, int(length_read * 0.8) - block_size - 1\n",
    "    else:  # split == 'test'\n",
    "        a, b, max_index = x_test, y_test, length_read - (int(length_read * 0.8) + block_size + 1)\n",
    "\n",
    "    # Generate random indices for batch selection, ensuring they're within bounds\n",
    "    ix = torch.randint(0, max_index, (batch_size,))\n",
    "    # Initialize lists to hold the batches\n",
    "    x_batch = []\n",
    "    y_batch = []\n",
    "\n",
    "    for i in ix:\n",
    "        try:\n",
    "            # Extract sequences from 'a' and 'b' and the corresponding target from 'b'\n",
    "            seq_A = torch.tensor(a.iloc[i.item():i.item() + block_size].astype(np.float32).values, dtype=torch.float32)\n",
    "            seq_B = torch.tensor(b.iloc[i.item():i.item()+1].astype(np.float32).values, dtype=torch.float32)\n",
    "            target = torch.tensor(b.iloc[i.item() + block_size].astype(np.float32).values, dtype=torch.float32)\n",
    "\n",
    "            seq = torch.cat((seq_A, seq_B), dim=0)\n",
    "            x_batch.append(seq)\n",
    "            y_batch.append(target)\n",
    "        except IndexError as e:\n",
    "            print(f\"IndexError for index {i.item()}: {str(e)}\")\n",
    "            print(f\"Attempting to access index [{i.item()}:{i.item() + block_size}] in 'a' with shape {a.shape}\")\n",
    "            print(f\"Attempting to access index {i.item() + block_size} in 'b' with shape {b.shape}\")\n",
    "            # Optionally, break or continue depending on desired behavior on error\n",
    "            break  # or continue\n",
    "\n",
    "    if not x_batch or not y_batch:\n",
    "        print(\"Error: Batch could not be created due to index issues.\")\n",
    "        return None, None\n",
    "\n",
    "    # Stack the collected sequences and targets into tensors\n",
    "    xstack = torch.stack(x_batch)\n",
    "    ystack = torch.stack(y_batch)\n",
    "\n",
    "    return xstack, ystack\n",
    "\n",
    "\n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, embed_size):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.embed_size = embed_size\n",
    "\n",
    "        self.keys = nn.Linear(embed_size, embed_size, bias=False)\n",
    "        self.queries = nn.Linear(embed_size, embed_size, bias=False)\n",
    "        self.values = nn.Linear(embed_size, embed_size, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        K = self.keys(x)\n",
    "        Q = self.queries(x)\n",
    "        V = self.values(x)\n",
    "\n",
    "        attention_scores = torch.matmul(Q, K.transpose(-2, -1)) / self.embed_size ** 0.5\n",
    "        attention = torch.softmax(attention_scores, dim=-1)\n",
    "\n",
    "        attended = torch.matmul(attention, V)\n",
    "        return attended\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, embed_size, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.embed_size = embed_size\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "        assert embed_size % num_heads == 0\n",
    "\n",
    "        self.head_dim = embed_size // num_heads\n",
    "\n",
    "        self.keys = nn.Linear(embed_size, embed_size, bias=False)\n",
    "        self.queries = nn.Linear(embed_size, embed_size, bias=False)\n",
    "        self.values = nn.Linear(embed_size, embed_size, bias=False)\n",
    "\n",
    "        self.fc_out = nn.Linear(embed_size, embed_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, seq_length, _ = x.shape\n",
    "        keys = self.keys(x).view(batch_size, seq_length, self.num_heads, self.head_dim)\n",
    "        queries = self.queries(x).view(batch_size, seq_length, self.num_heads, self.head_dim)\n",
    "        values = self.values(x).view(batch_size, seq_length, self.num_heads, self.head_dim)\n",
    "\n",
    "        attention_scores = torch.einsum(\"bnqh,bnkh->bnqk\", [queries, keys]) / (self.head_dim ** 0.5)\n",
    "        attention = torch.softmax(attention_scores, dim=-1)\n",
    "\n",
    "        attended = torch.einsum(\"bnqk,bnkv->bnqv\", [attention, values]).reshape(batch_size, seq_length, self.embed_size)\n",
    "\n",
    "        output = self.fc_out(attended)\n",
    "        return output\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch3(split)\n",
    "            X, Y = X.to(device), Y.to(device)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train\n",
    "    del X, Y\n",
    "    return out\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, embed_size, num_heads):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.norm1 = nn.LayerNorm(embed_size)\n",
    "        self.attention = MultiHeadAttention(embed_size, num_heads)\n",
    "        self.dropout1 = nn.Dropout(0.1)\n",
    "\n",
    "        self.norm2 = nn.LayerNorm(embed_size)\n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(embed_size, 2 * embed_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2 * embed_size, embed_size),\n",
    "        )\n",
    "        self.dropout2 = nn.Dropout(0.1)\n",
    "\n",
    "    def forward(self, value):\n",
    "        x = self.norm1(value)\n",
    "        attention_output = self.attention(x)\n",
    "        x = value + self.dropout1(attention_output)  # Residual connection and dropout after attention\n",
    "        x = self.norm2(x)\n",
    "        feed_forward_output = self.feed_forward(x)\n",
    "        out = value + self.dropout2(feed_forward_output)  # Residual connection and dropout after FFN\n",
    "        return out\n",
    "\n",
    "# Positional Encoding in Encoder class should be moved to the device\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_feature_dim, embed_size, num_heads, num_layers, seq_length):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.input_fc = nn.Linear(input_feature_dim, embed_size)\n",
    "        self.positional_encoding = nn.Parameter(torch.randn(1, seq_length, embed_size)).to(device)\n",
    "        self.layers = nn.ModuleList([\n",
    "            TransformerBlock(embed_size, num_heads) for _ in range(num_layers)])\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.input_fc(x)) + self.positional_encoding\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "    \n",
    "    def to_cpu(self):\n",
    "        # Move the entire model to CPU\n",
    "        self.input_fc.to('cpu')\n",
    "        self.positional_encoding.data = self.positional_encoding.data.cpu()\n",
    "        for layer in self.layers:\n",
    "            layer.to('cpu')\n",
    "        self.relu.to('cpu')\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "class EncoderDecoderModelWithMultiHeadAttention(nn.Module):\n",
    "    def __init__(self, input_feature_dim, embed_size, target_dim, seq_length, num_heads, num_layers):\n",
    "        super(EncoderDecoderModelWithMultiHeadAttention, self).__init__()\n",
    "        self.encoder = Encoder(input_feature_dim, embed_size, num_heads, num_layers, seq_length)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(embed_size, target_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, targets):\n",
    "        encoded = self.encoder(x)\n",
    "        encoded_pooled = torch.mean(encoded, dim=1)\n",
    "        decoded = self.decoder(encoded_pooled)\n",
    "        \n",
    "        if targets is not None:\n",
    "            loss = criterion(decoded, targets)  \n",
    "            return decoded, loss\n",
    "\n",
    "        return decoded, None\n",
    "\n",
    "    def to_cpu(self):\n",
    "        self.encoder.to_cpu()\n",
    "        for layer in self.decoder:\n",
    "            layer.to('cpu')\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "\n",
    "\n",
    "actuals = []\n",
    "predictions = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf42854-0b8c-44c8-aab8-6a6fbcc6fc8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: train loss 3.3931, val loss 2.2935\n",
      "step 10: train loss 0.4373, val loss 0.3902\n",
      "step 20: train loss 0.4184, val loss 0.5293\n",
      "step 30: train loss 0.3591, val loss 0.4907\n",
      "step 40: train loss 0.2856, val loss 0.3018\n",
      "step 50: train loss 0.3032, val loss 0.3321\n",
      "step 60: train loss 0.2965, val loss 0.3008\n",
      "step 70: train loss 0.3544, val loss 0.3565\n",
      "step 80: train loss 0.3102, val loss 0.2771\n",
      "step 90: train loss 0.3159, val loss 0.2405\n",
      "step 100: train loss 0.2700, val loss 0.3180\n",
      "step 110: train loss 0.2488, val loss 0.3788\n",
      "step 120: train loss 0.2474, val loss 0.2673\n",
      "step 130: train loss 0.2652, val loss 0.2217\n",
      "step 140: train loss 0.3330, val loss 0.3862\n",
      "step 150: train loss 0.2559, val loss 0.2575\n",
      "step 160: train loss 0.2401, val loss 0.2805\n",
      "step 170: train loss 0.2748, val loss 0.3314\n",
      "step 180: train loss 0.2399, val loss 0.3323\n",
      "step 190: train loss 0.2344, val loss 0.2869\n",
      "step 200: train loss 0.2376, val loss 0.3745\n",
      "step 210: train loss 0.2417, val loss 0.3865\n",
      "step 220: train loss 0.2275, val loss 0.3684\n",
      "step 230: train loss 0.2500, val loss 0.3274\n",
      "step 240: train loss 0.2045, val loss 0.2216\n",
      "step 250: train loss 0.1857, val loss 0.2895\n",
      "step 260: train loss 0.1799, val loss 0.3251\n",
      "step 270: train loss 0.2142, val loss 0.3150\n",
      "step 280: train loss 0.2020, val loss 0.3737\n",
      "step 290: train loss 0.1861, val loss 0.3063\n",
      "step 300: train loss 0.1809, val loss 0.2705\n",
      "step 310: train loss 0.1656, val loss 0.2948\n",
      "step 320: train loss 0.1495, val loss 0.2440\n",
      "step 330: train loss 0.1772, val loss 0.3612\n",
      "step 340: train loss 0.1572, val loss 0.3380\n",
      "step 350: train loss 0.1402, val loss 0.2256\n",
      "step 360: train loss 0.1516, val loss 0.3238\n",
      "step 370: train loss 0.1292, val loss 0.2511\n",
      "step 380: train loss 0.1320, val loss 0.2300\n",
      "step 390: train loss 0.1399, val loss 0.3426\n",
      "step 400: train loss 0.1119, val loss 0.3185\n",
      "step 410: train loss 0.1235, val loss 0.2605\n",
      "step 420: train loss 0.1211, val loss 0.2072\n",
      "step 430: train loss 0.1093, val loss 0.2595\n",
      "step 440: train loss 0.1182, val loss 0.2028\n",
      "step 450: train loss 0.1182, val loss 0.2290\n",
      "step 460: train loss 0.1022, val loss 0.1759\n",
      "step 470: train loss 0.0954, val loss 0.1988\n",
      "step 480: train loss 0.0990, val loss 0.2964\n",
      "step 490: train loss 0.0961, val loss 0.2126\n",
      "step 500: train loss 0.0856, val loss 0.2430\n",
      "step 510: train loss 0.0752, val loss 0.2358\n",
      "step 520: train loss 0.0731, val loss 0.2926\n",
      "step 530: train loss 0.0714, val loss 0.2170\n",
      "step 540: train loss 0.0702, val loss 0.2175\n",
      "step 550: train loss 0.0635, val loss 0.1889\n",
      "step 560: train loss 0.0607, val loss 0.2392\n",
      "step 570: train loss 0.0531, val loss 0.1997\n",
      "step 580: train loss 0.0497, val loss 0.2263\n",
      "step 590: train loss 0.0588, val loss 0.1775\n",
      "step 600: train loss 0.0568, val loss 0.1874\n",
      "step 610: train loss 0.0530, val loss 0.1919\n",
      "step 620: train loss 0.0521, val loss 0.2113\n",
      "step 630: train loss 0.0527, val loss 0.2421\n",
      "step 640: train loss 0.0478, val loss 0.2300\n",
      "step 650: train loss 0.0409, val loss 0.2206\n",
      "step 660: train loss 0.0411, val loss 0.2171\n",
      "step 670: train loss 0.0412, val loss 0.1986\n",
      "step 680: train loss 0.0401, val loss 0.1991\n",
      "step 690: train loss 0.0353, val loss 0.1846\n",
      "step 700: train loss 0.0370, val loss 0.2037\n",
      "step 710: train loss 0.0375, val loss 0.1785\n",
      "step 720: train loss 0.0409, val loss 0.1966\n",
      "step 730: train loss 0.0420, val loss 0.2057\n",
      "step 740: train loss 0.0363, val loss 0.2010\n",
      "step 750: train loss 0.0316, val loss 0.1967\n",
      "step 760: train loss 0.0404, val loss 0.1823\n",
      "step 770: train loss 0.0392, val loss 0.1971\n",
      "step 780: train loss 0.0310, val loss 0.1731\n",
      "step 790: train loss 0.0347, val loss 0.1905\n",
      "step 800: train loss 0.0294, val loss 0.1980\n",
      "step 810: train loss 0.0302, val loss 0.2010\n",
      "step 820: train loss 0.0310, val loss 0.2329\n",
      "step 830: train loss 0.0301, val loss 0.1804\n",
      "step 840: train loss 0.0296, val loss 0.1832\n",
      "step 850: train loss 0.0304, val loss 0.1793\n",
      "step 860: train loss 0.0295, val loss 0.1850\n",
      "step 870: train loss 0.0298, val loss 0.1872\n",
      "step 880: train loss 0.0281, val loss 0.1879\n",
      "step 890: train loss 0.0314, val loss 0.1632\n",
      "step 900: train loss 0.0333, val loss 0.1621\n",
      "step 910: train loss 0.0284, val loss 0.1951\n",
      "step 920: train loss 0.0276, val loss 0.1780\n",
      "step 930: train loss 0.0257, val loss 0.1751\n",
      "step 940: train loss 0.0235, val loss 0.2239\n",
      "step 950: train loss 0.0292, val loss 0.1649\n",
      "step 960: train loss 0.0240, val loss 0.2019\n",
      "step 970: train loss 0.0236, val loss 0.1658\n",
      "step 980: train loss 0.0225, val loss 0.1837\n",
      "step 990: train loss 0.0217, val loss 0.1899\n",
      "step 1000: train loss 0.0375, val loss 0.2289\n",
      "step 1010: train loss 0.0378, val loss 0.1965\n",
      "step 1020: train loss 0.0286, val loss 0.1943\n",
      "step 1030: train loss 0.0313, val loss 0.2097\n",
      "step 1040: train loss 0.0242, val loss 0.1511\n",
      "step 1050: train loss 0.0228, val loss 0.2025\n",
      "step 1060: train loss 0.0198, val loss 0.1830\n",
      "step 1070: train loss 0.0216, val loss 0.1615\n",
      "step 1080: train loss 0.0334, val loss 0.2249\n",
      "step 1090: train loss 0.0256, val loss 0.1723\n",
      "step 1100: train loss 0.0241, val loss 0.1697\n",
      "step 1110: train loss 0.0258, val loss 0.2281\n",
      "step 1120: train loss 0.0234, val loss 0.1800\n",
      "step 1130: train loss 0.0257, val loss 0.1827\n",
      "step 1140: train loss 0.0210, val loss 0.2066\n",
      "step 1150: train loss 0.0186, val loss 0.2014\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    model = EncoderDecoderModelWithMultiHeadAttention(input_feature_dim, embed_size, target_dim, block_size+1, num_heads, num_layers).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    for iter in range(max_iters):\n",
    "        # Evaluate the loss periodically\n",
    "        if iter % eval_interval == 0 or iter == max_iters - 1:\n",
    "            losses = estimate_loss()\n",
    "            print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "\n",
    "        xb, yb = get_batch3('train')\n",
    "        xb, yb = xb.to(device), yb.to(device)  # Ensure these tensors are on the correct device\n",
    "\n",
    "        predictions, loss = model(xb, yb)\n",
    "        \n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "                # After using tensors in a training step\n",
    "        del xb, yb, predictions  # Assuming these are not needed after the training step\n",
    "        clean_memory()  # Call this to clear memoryq\n",
    "    print(\"Loss:\", loss.item())\n",
    "    del loss  # Assuming these are not needed after the training step\n",
    "    clean_memory()  # Call this to clear memoryq\n",
    "    model.to_cpu()\n",
    "    # Save the model\n",
    "    model_path = \"C:/Users/yueze/Desktop/trained_model.pth\"\n",
    "    torch.save(model, model_path)\n",
    "\n",
    "    print(\"Model saved to\", model_path)\n",
    "    \n",
    "    # To load the model later\n",
    "    # model = EncoderDecoderModelWithMultiHeadAttention(input_feature_dim, embed_size, target_dim, block_size*2+2, num_heads, num_layers)\n",
    "    # model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    # model.to(device)\n",
    "    # print(\"Model loaded from\", model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b75e00-c40c-431e-842d-582ee346e838",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_full_dataset(x, y, block_size,length):\n",
    "    full_sequences = []\n",
    "    for i in range(length - block_size + 1):\n",
    "        seq = torch.tensor(x.iloc[i:i + block_size].astype(np.float32).values)\n",
    "        seq2 = torch.tensor(y.iloc[i:i + 1].astype(np.float32).values)\n",
    "        combined_seq = torch.cat((seq, seq2), dim=0)\n",
    "        full_sequences.append(combined_seq)\n",
    "    \n",
    "    full_dataset = torch.stack(full_sequences)\n",
    "    return full_dataset\n",
    "\n",
    "# Prepare the full dataset and send it to the correct device\n",
    "x_full = prepare_full_dataset(df[features],df[targets], block_size,500000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e959625-57e9-4a6b-b5da-9f7e142ff845",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1000\n",
    "num_samples = x_full.size(0)  # Get the total number of samples\n",
    "all_predictions = []\n",
    "\n",
    "model.to_cpu()  # Ensure the model is on the CPU\n",
    "\n",
    "with torch.no_grad():\n",
    "    for start_idx in range(0, num_samples, batch_size):\n",
    "        end_idx = min(start_idx + batch_size, num_samples)  # Calculate the end index of the batch\n",
    "        batch_x = x_full[start_idx:end_idx]  # Extract the batch\n",
    "        predictions_batch, _ = model(batch_x, None)  # Get predictions for the batch\n",
    "        all_predictions.append(predictions_batch.cpu())  # Collect the predictions\n",
    "\n",
    "# Concatenate all batch predictions into a single tensor\n",
    "predictions_full = torch.cat(all_predictions, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db98877d-3b5f-48cf-bdd9-006213edc0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "AI0 = predictions_full[:, 0].numpy()\n",
    "AI1 = predictions_full[:, 1].numpy()\n",
    "AI2 = predictions_full[:, 2].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb093024-1a6c-46be-b251-a0f61b4e9d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(df[\"AI0\"][0:500000])\n",
    "plt.title('Feature AI0')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f2041d-f473-44ee-95b3-ab20ffd34244",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(AI0)\n",
    "plt.title('predicted ai0')\n",
    "plt.xlabel('Sequence Index')\n",
    "plt.ylabel('Value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96605a7-86ed-4567-a025-a243141fa515",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(df[\"AI1\"][0:500000])\n",
    "plt.title('Feature AI1')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Value')\n",
    "plt.show()\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(AI1)\n",
    "plt.title('ai1')\n",
    "plt.xlabel('Sequence Index')\n",
    "plt.ylabel('Value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bdc966-bbbb-45f3-b9ac-3b14a5662a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(df[\"AI2\"][20000:20500])\n",
    "plt.title('Feature AI2')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Value')\n",
    "plt.show()\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(AI2[20000:20500])\n",
    "plt.title('ai2')\n",
    "plt.xlabel('Sequence Index')\n",
    "plt.ylabel('Value')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ca457f-54d0-4b77-95b7-e8778b314149",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
